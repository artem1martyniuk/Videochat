import torch.nn as nn
import torch.nn.functional as F
import torch
class UNet(nn.Module):
   def __init__(self):
       super(UNet, self).__init__()
       self.c1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
       self.c2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
       self.c3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
       self.c4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
       self.c5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)
       self.pool = nn.MaxPool2d(2, 2)
       self.bottleneck = nn.Conv2d(512, 1024, kernel_size=3, padding=1)
       self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
       self.conv_up1 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)
       self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
       self.conv_up2 = nn.Conv2d(512, 256, kernel_size=3, padding=1)
       self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
       self.conv_up3 = nn.Conv2d(256, 128, kernel_size=3, padding=1)
       self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
       self.conv_up4 = nn.Conv2d(128, 64, kernel_size=3, padding=1)
       self.up5 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)
       self.conv_up5 = nn.Conv2d(64, 32, kernel_size=3, padding=1)
       self.final_conv = nn.Conv2d(32, 1, kernel_size=1)
       
   def forward(self, x):
       c1 = F.relu(self.c1(x))
       c1p = self.pool(c1)
       c2 = F.relu(self.c2(c1p))
       c2p = self.pool(c2)
       c3 = F.relu(self.c3(c2p))
       c3p = self.pool(c3)
       c4 = F.relu(self.c4(c3p))
       c4p = self.pool(c4)
       c5 = F.relu(self.c5(c4p))
       c5p = self.pool(c5)
       b = F.relu(self.bottleneck(c5p))
       d1 = self.up1(b)
       d1 = torch.cat([d1, c5], dim=1)
       d1 = F.relu(self.conv_up1(d1))
       d2 = self.up2(d1)
       d2 = torch.cat([d2, c4], dim=1)
       d2 = F.relu(self.conv_up2(d2))
       d3 = self.up3(d2)
       d3 = torch.cat([d3, c3], dim=1)
       d3 = F.relu(self.conv_up3(d3))
       d4 = self.up4(d3)
       d4 = torch.cat([d4, c2], dim=1)
       d4 = F.relu(self.conv_up4(d4))
       d5 = self.up5(d4)
       d5 = torch.cat([d5, c1], dim=1)
       d5 = F.relu(self.conv_up5(d5))
       out = self.final_conv(d5)
       return out
